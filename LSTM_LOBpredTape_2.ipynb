{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载函数\n",
    "def load_and_process_data(lob_path, tape_path):\n",
    "    # Load LOB data\n",
    "    Feature_UoB_Set01_LOBs = pd.read_csv(lob_path).dropna()\n",
    "    Feature_UoB_Set01_LOBs = Feature_UoB_Set01_LOBs.reset_index().drop(\"index\", axis=1)\n",
    "    \n",
    "    # Load Tape data\n",
    "    clean_uob_set01_tapes = pd.read_csv(tape_path)\n",
    "    \n",
    "    # Resample and adjust function\n",
    "    def resample_and_adjust_using_original_times(df, target_count):\n",
    "        # Assuming 'Time' is in seconds and 'Weighted_Price' is the price\n",
    "        df['Time_bin'] = (df['Time'] // 10 * 10).astype(int)\n",
    "        \n",
    "        # Ensure the range includes 0-10 seconds bin\n",
    "        all_time_bins = range(0, df['Time_bin'].max() + 10, 10)  # Starts from 0 now\n",
    "        grouped = df.groupby('Time_bin')\n",
    "        \n",
    "        new_records = []\n",
    "        last_known_price = df['Weighted_Price'].iloc[0]  # Initialize with the first known price\n",
    "        \n",
    "        # Iterate through all possible time bins\n",
    "        for time_bin in all_time_bins:\n",
    "            if time_bin in grouped.groups:\n",
    "                group = grouped.get_group(time_bin)\n",
    "                times = group['Time'].values\n",
    "                prices = group['Weighted_Price'].values\n",
    "                if len(prices) > 0:\n",
    "                    last_known_price = prices[-1]\n",
    "            else:\n",
    "                group = None\n",
    "            \n",
    "            # If the current time bin is empty or has only one price data point\n",
    "            if group is None or len(prices) == 0:\n",
    "                prices = np.full(target_count, last_known_price)\n",
    "                times = np.linspace(time_bin, time_bin + 9, num=target_count)\n",
    "            elif len(prices) == 1:\n",
    "                times = np.linspace(time_bin, time_bin + 9, num=target_count)\n",
    "                prices = np.full(target_count, last_known_price)\n",
    "            else:\n",
    "                # If there are fewer data points than the target count, additional points will be added\n",
    "                while len(prices) < target_count:\n",
    "                    time_diffs = np.diff(times)\n",
    "                    idx_to_fill = np.argmax(time_diffs)\n",
    "                    new_time = (times[idx_to_fill] + times[idx_to_fill + 1]) / 2\n",
    "                    new_price = (prices[idx_to_fill] + prices[idx_to_fill + 1]) / 2\n",
    "                    times = np.insert(times, idx_to_fill + 1, new_time)\n",
    "                    prices = np.insert(prices, idx_to_fill + 1, new_price)\n",
    "                # If there are multiple data points within the time bin, proceed with normal processing\n",
    "                while len(prices) > target_count:\n",
    "                    time_diffs = np.diff(times)\n",
    "                    idx_to_merge = np.argmin(time_diffs)\n",
    "                    new_time = (times[idx_to_merge] + times[idx_to_merge + 1]) / 2\n",
    "                    new_price = (prices[idx_to_merge] + prices[idx_to_merge + 1]) / 2\n",
    "                    times = np.delete(times, [idx_to_merge, idx_to_merge + 1])\n",
    "                    times = np.insert(times, idx_to_merge, new_time)\n",
    "                    prices = np.delete(prices, [idx_to_merge, idx_to_merge + 1])\n",
    "                    prices = np.insert(prices, idx_to_merge, new_price)\n",
    "            # Add the processed data to the results list          \n",
    "            new_records.extend(zip(times, prices))\n",
    "    \n",
    "        new_df = pd.DataFrame(new_records, columns=['Time', 'Weighted_Price'])\n",
    "        new_df.sort_values('Time', inplace=True)\n",
    "        return new_df\n",
    "\n",
    "\n",
    "    # Resample the data\n",
    "    processed_df = resample_and_adjust_using_original_times(clean_uob_set01_tapes, 6)\n",
    "    \n",
    "    \n",
    "    # Create dataset function\n",
    "    def create_dataset(data, time_step, step=6):\n",
    "        X, y = [], []\n",
    "        for i in range(0, len(data)-time_step, step):\n",
    "            X.append(data[i:(i+time_step), 0])\n",
    "            y.append(data[(i+time_step):(i+time_step+6), 0])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    price = processed_df['Weighted_Price'].values.reshape(-1, 1)\n",
    "    time_step = 360\n",
    "    _, tags = create_dataset(price, time_step, step=6)\n",
    "\n",
    "    # 重点重点！！！！！！！！！！Feature scaling不能放在循环里！\n",
    "    #scaler = MinMaxScaler()\n",
    "    #features = scaler.fit_transform(Feature_UoB_Set01_LOBs)\n",
    "    #targets = scaler.fit_transform(tags)\n",
    "    features = Feature_UoB_Set01_LOBs\n",
    "    targets = tags\n",
    "\n",
    "    np.save(lob_path[-18:-4]+'_features.npy', features)\n",
    "    np.save(tape_path[-19:-4]+'_targets.npy', targets)\n",
    "    \n",
    "    return features, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(directory0, directory1):\n",
    "    files_lob = os.listdir(directory0)\n",
    "    files_tape = os.listdir(directory1)\n",
    "    \n",
    "    for file_lob, file_tape in zip(files_lob, files_tape):\n",
    "        file_path0 = os.path.join(directory0, file_lob)\n",
    "        file_path1 = os.path.join(directory1, file_tape)\n",
    "        print(\"Processing: \", file_path0, \" and \", file_path1)\n",
    "        load_and_process_data(file_path0, file_path1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(source_dir, lobs_dir, tapes_dir):\n",
    "    if not os.path.exists(lobs_dir):\n",
    "        os.makedirs(lobs_dir)\n",
    "    if not os.path.exists(tapes_dir):\n",
    "        os.makedirs(tapes_dir)\n",
    "\n",
    "    # 遍历源目录中的所有文件\n",
    "    for file in os.listdir(source_dir):\n",
    "        full_file_path = os.path.join(source_dir, file)\n",
    "        if os.path.isfile(full_file_path):\n",
    "            if file.endswith(\"features.npy\"):\n",
    "                # 移动文件到lobs_dir\n",
    "                shutil.move(full_file_path, os.path.join(lobs_dir, file))\n",
    "                print(f\"Moved {file} to {lobs_dir}\")\n",
    "            elif file.endswith(\"targets.npy\"):\n",
    "                # 移动文件到tapes_dir\n",
    "                shutil.move(full_file_path, os.path.join(tapes_dir, file))\n",
    "                print(f\"Moved {file} to {tapes_dir}\")\n",
    "            else:\n",
    "                print(f\"Skipped {file}, did not match criteria.\")\n",
    "        else:\n",
    "            print(f\"Skipping directory: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train数据集预处理\n",
    "preprocess(\"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\train\\\\lobs\", \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\train\\\\tapes\")\n",
    "\n",
    "\n",
    "source_directory = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\"\n",
    "train_lob_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\train\\\\lobs\"\n",
    "train_tape_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\train\\\\tapes\"\n",
    "\n",
    "# 移动文件\n",
    "move_files(source_directory, train_lob_dir, train_tape_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-04-28LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-04-28tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-04-29LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-04-29tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-04-30LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-04-30tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-01LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-01tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-02LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-02tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-06LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-06tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-07LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-07tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-08LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-08tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-09LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-09tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-12LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-12tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-13LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-13tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-14LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-14tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-15LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-15tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-16LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-16tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-19LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-19tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-20LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-20tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-21LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-21tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-22LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-22tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-23LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-23tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\lobs\\Featured_Clean_UoB_Set01_2025-05-27LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\validate\\tapes\\Clean_UoB_Set01_2025-05-27tapes.csv\n",
      "Moved 2025-04-28LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-04-28tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-04-29LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-04-29tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-04-30LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-04-30tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-01LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-01tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-02LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-02tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-06LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-06tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-07LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-07tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-08LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-08tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-09LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-09tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-12LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-12tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-13LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-13tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-14LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-14tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-15LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-15tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-16LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-16tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-19LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-19tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-20LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-20tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-21LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-21tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-22LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-22tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-23LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-23tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Moved 2025-05-27LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\lobs\n",
      "Moved 2025-05-27tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\validate\\tapes\n",
      "Skipping directory: discard\n",
      "Skipping directory: HelloWorld\n",
      "Skipped LSTM_LOBpredTape_2.ipynb, did not match criteria.\n",
      "Skipping directory: train\n",
      "Skipping directory: validate\n"
     ]
    }
   ],
   "source": [
    "# validate数据集预处理\n",
    "preprocess(\"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\validate\\\\lobs\", \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\validate\\\\tapes\")\n",
    "\n",
    "\n",
    "source_directory = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\"\n",
    "validate_lob_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\validate\\\\lobs\"\n",
    "validate_tape_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\validate\\\\tapes\"\n",
    "\n",
    "# 移动文件\n",
    "move_files(source_directory, validate_lob_dir, validate_tape_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-05-28LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-05-28tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-05-29LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-05-29tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-05-30LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-05-30tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-02LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-02tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-03LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-03tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-04LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-04tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-05LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-05tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-06LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-06tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-09LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-09tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-10LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-10tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-11LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-11tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-12LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-12tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-13LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-13tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-16LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-16tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-17LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-17tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-18LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-18tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-19LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-19tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-20LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-20tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-23LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-23tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-24LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-24tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-25LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-25tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-26LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-26tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-27LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-27tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-06-30LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-06-30tapes.csv\n",
      "Processing:  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\lobs\\Featured_Clean_UoB_Set01_2025-07-01LOBs.txt  and  C:\\Users\\zoec0\\Desktop\\DSMP\\data\\test\\tapes\\Clean_UoB_Set01_2025-07-01tapes.csv\n",
      "Moved 2025-05-28LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-05-28tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-05-29LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-05-29tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-05-30LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-05-30tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-02LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-02tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-03LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-03tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-04LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-04tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-05LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-05tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-06LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-06tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-09LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-09tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-10LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-10tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-11LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-11tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-12LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-12tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-13LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-13tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-16LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-16tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-17LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-17tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-18LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-18tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-19LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-19tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-20LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-20tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-23LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-23tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-24LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-24tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-25LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-25tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-26LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-26tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-27LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-27tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-06-30LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-06-30tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Moved 2025-07-01LOBs_features.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\lobs\n",
      "Moved 2025-07-01tapes_targets.npy to C:\\Users\\zoec0\\Desktop\\DSMP\\新建文件夹\\test\\tapes\n",
      "Skipping directory: discard\n",
      "Skipping directory: HelloWorld\n",
      "Skipped LSTM_LOBpredTape_2.ipynb, did not match criteria.\n",
      "Skipping directory: test\n",
      "Skipping directory: train\n",
      "Skipping directory: validate\n"
     ]
    }
   ],
   "source": [
    "# test数据集预处理\n",
    "preprocess(\"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\test\\\\lobs\", \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\data\\\\test\\\\tapes\")\n",
    "\n",
    "\n",
    "source_directory = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\"\n",
    "test_lob_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\test\\\\lobs\"\n",
    "test_tape_dir = \"C:\\\\Users\\\\zoec0\\\\Desktop\\\\DSMP\\\\新建文件夹\\\\test\\\\tapes\"\n",
    "\n",
    "# 移动文件\n",
    "move_files(source_directory, test_lob_dir, test_tape_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train合并成两个大的dataframe\n",
    "\n",
    "# 指定文件夹的路径\n",
    "train_LOBs_path = \"train/lobs\"\n",
    "train_Tapes_path = \"train/tapes\"\n",
    "\n",
    "# 读取文件夹中所有的.npy文件\n",
    "files_train_LOBs = [f for f in os.listdir(train_LOBs_path) if f.endswith('.npy')]\n",
    "files_train_Tapes = [f for f in os.listdir(train_Tapes_path) if f.endswith('.npy')]\n",
    "\n",
    "# 初始化空的DataFrames\n",
    "train_LOBs_df = pd.DataFrame()\n",
    "train_Tapes_df = pd.DataFrame()\n",
    "\n",
    "# 遍历文件列表，加载每个文件并追加到DataFrame\n",
    "for file in files_train_LOBs:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(train_LOBs_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_LOBs_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    train_LOBs_df = pd.concat([train_LOBs_df, temp_LOBs_df], ignore_index=True)\n",
    "\n",
    "for file in files_train_Tapes:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(train_Tapes_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_Tapes_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    train_Tapes_df = pd.concat([train_Tapes_df, temp_Tapes_df], ignore_index=True)\n",
    "\n",
    "# 保存成文件\n",
    "train_LOBs_df.to_csv('train_LOBs_df.csv')\n",
    "train_Tapes_df.to_csv('train_Tapes_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate合并成两个大的dataframe\n",
    "\n",
    "# 指定文件夹的路径\n",
    "valid_LOBs_path = \"validate/lobs\"\n",
    "valid_Tapes_path = \"validate/tapes\"\n",
    "\n",
    "# 读取文件夹中所有的.npy文件\n",
    "files_valid_LOBs = [f for f in os.listdir(valid_LOBs_path) if f.endswith('.npy')]\n",
    "files_valid_Tapes = [f for f in os.listdir(valid_Tapes_path) if f.endswith('.npy')]\n",
    "\n",
    "# 初始化空的DataFrames\n",
    "valid_LOBs_df = pd.DataFrame()\n",
    "valid_Tapes_df = pd.DataFrame()\n",
    "\n",
    "# 遍历文件列表，加载每个文件并追加到DataFrame\n",
    "for file in files_valid_LOBs:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(valid_LOBs_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_LOBs_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    valid_LOBs_df = pd.concat([valid_LOBs_df, temp_LOBs_df], ignore_index=True)\n",
    "\n",
    "for file in files_valid_Tapes:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(valid_Tapes_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_Tapes_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    valid_Tapes_df = pd.concat([valid_Tapes_df, temp_Tapes_df], ignore_index=True)\n",
    "\n",
    "# 保存成文件\n",
    "valid_LOBs_df.to_csv('valid_LOBs_df.csv')\n",
    "valid_Tapes_df.to_csv('valid_Tapes_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test合并成两个大的dataframe\n",
    "\n",
    "# 指定文件夹的路径\n",
    "test_LOBs_path = \"test/lobs\"\n",
    "test_Tapes_path = \"test/tapes\"\n",
    "\n",
    "# 读取文件夹中所有的.npy文件\n",
    "files_test_LOBs = [f for f in os.listdir(test_LOBs_path) if f.endswith('.npy')]\n",
    "files_test_Tapes = [f for f in os.listdir(test_Tapes_path) if f.endswith('.npy')]\n",
    "\n",
    "# 初始化空的DataFrames\n",
    "test_LOBs_df = pd.DataFrame()\n",
    "test_Tapes_df = pd.DataFrame()\n",
    "\n",
    "# 遍历文件列表，加载每个文件并追加到DataFrame\n",
    "for file in files_test_LOBs:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(test_LOBs_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_LOBs_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    test_LOBs_df = pd.concat([test_LOBs_df, temp_LOBs_df], ignore_index=True)\n",
    "\n",
    "for file in files_test_Tapes:\n",
    "    # 加载.npy文件\n",
    "    data = np.load(os.path.join(test_Tapes_path, file))\n",
    "    # 将numpy数组转换为DataFrame\n",
    "    temp_Tapes_df = pd.DataFrame(data)\n",
    "    # 追加到主DataFrame\n",
    "    test_Tapes_df = pd.concat([test_Tapes_df, temp_Tapes_df], ignore_index=True)\n",
    "\n",
    "# 保存成文件\n",
    "test_LOBs_df.to_csv('test_LOBs_df.csv')\n",
    "test_Tapes_df.to_csv('test_Tapes_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 横着合并lobs和tapes\n",
    "# 此时csv文件未拟合\n",
    "\n",
    "train_df = pd.concat([train_LOBs_df,train_Tapes_df],axis=1)\n",
    "train_df.to_csv('train_df.csv')\n",
    "\n",
    "valid_df = pd.concat([valid_LOBs_df,valid_Tapes_df],axis=1)\n",
    "valid_df.to_csv('valid_df.csv')\n",
    "\n",
    "test_df = pd.concat([test_LOBs_df,test_Tapes_df],axis=1)\n",
    "test_df.to_csv('test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit train\n",
    "scaler.fit(train_df)\n",
    "\n",
    "train_df = scaler.transform(train_df)\n",
    "\n",
    "valid_df = scaler.transform(valid_df)\n",
    "\n",
    "test_df = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 模型构建\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(248, 1)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(30, return_sequences=False),\n",
    "    Dense(6)  # 输出维度为6\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译优化\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (240000, 248)\n",
      "y_train shape: (240000, 6)\n"
     ]
    }
   ],
   "source": [
    "# 分训练集数据\n",
    "X_train = train_df[:, :248]  # 选择前248列作为X_train\n",
    "\n",
    "y_train = train_df[:, -6:]   # 选择最后6列作为y_train\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid shape: (60000, 248)\n",
      "y_valid shape: (60000, 6)\n"
     ]
    }
   ],
   "source": [
    "# 分验证集数据\n",
    "X_valid = valid_df[:, :248]\n",
    "\n",
    "y_valid = valid_df[:, -6:]\n",
    "\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (75000, 248)\n",
      "y_test shape: (75000, 6)\n"
     ]
    }
   ],
   "source": [
    "# 分测试集数据\n",
    "X_test = test_df[:, :248]\n",
    "\n",
    "y_test = test_df[:, -6:]\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化用于存储验证损失的列表\n",
    "val_losses = []\n",
    "\n",
    "# 创建ModelCheckpoint实例\n",
    "checkpoint_path = f\"checkpoints/model-epoch{{epoch:03d}}-val_loss{{val_loss:.4f}}.keras\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,       # 检查点文件的保存路径\n",
    "    monitor='val_loss',             # 监控的数据是验证集loss\n",
    "    save_best_only=False,           # 保存所有模型，不仅仅是最好的模型\n",
    "    save_weights_only=False,         # 保存完整模型\n",
    "    mode='auto',\n",
    "    verbose=1)                      # 打印详细日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0091\n",
      "Epoch 1: saving model to checkpoints/model-epoch001-val_loss0.0017.keras\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 154ms/step - loss: 0.0091 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "\u001b[1m3281/7500\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m10:31\u001b[0m 150ms/step - loss: 0.0013"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10856\\2030903432.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 模型训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    327\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m                     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m                     callbacks.on_train_batch_end(\n\u001b[0;32m    331\u001b[0m                         \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    876\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m       )\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   )\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1321\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mflat_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1501\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[checkpoint_callback]     # 使用checkpoint回调/每次周期保存模型\n",
    ")\n",
    "\n",
    "# 提取并存储每个周期的验证损失\n",
    "val_losses = history.history['val_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation losses saved.\n"
     ]
    }
   ],
   "source": [
    "# 在所有训练完成后，将val_loss保存到CSV文件\n",
    "val_loss_df = pd.DataFrame(val_losses, columns=['val_loss'])\n",
    "val_loss_df.to_csv('validation_losses.csv', index_label='epoch')\n",
    "print(f\"Validation losses saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要补充的！！！！！\n",
    "# 可视化val_loss，选出最好的模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最优模型\n",
    "model_path = 'checkpoints/model-epoch001-val_loss0.0017.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# 初始化评估指标列表\n",
    "mse_scores = []\n",
    "rmse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要改的！！！！！！！！！！\n",
    "for lobs_test_file, tapes_test_file in zip(lobs_test_files, tapes_test_files):\n",
    "    test_lobs_path = os.path.join(test_lobs_dir, lobs_test_file)\n",
    "    test_tapes_path = os.path.join(test_tapes_dir, tapes_test_file)\n",
    "    \n",
    "    # 加载数据改改改！！！！！！！！！！！！！\n",
    "    X_test = np.load(test_lobs_path)\n",
    "    y_true = np.load(test_tapes_path)  # 真实的tapes数据\n",
    "    \n",
    "    # 使用模型进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 如果预测输出需要被逆变换（确保预测输出的形状适用于scaler）\n",
    "    y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "    y_true_rescaled = scaler.inverse_transform(y_true.reshape(-1, 1))\n",
    "    \n",
    "    # 计算MSE和RMSE\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    \n",
    "    # 可视化预测结果与真实数据\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(y_true_rescaled, label='Actual Weighted Price', color='blue', linewidth=1)\n",
    "    plt.plot(y_pred_rescaled, label='Predicted Weighted Price', color='red', linestyle='--', linewidth=1)\n",
    "    plt.title(f'Prediction vs True Data for {tapes_test_file}')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Weighted Price')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 保存图像\n",
    "    save_path = os.path.join('predictions_visualizations', f\"{tapes_test_file}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()  # 关闭图形以节省内存\n",
    "    \n",
    "    print(f\"Saved visualization for {tapes_test_file} at {save_path}\")\n",
    "    print(f\"MSE for {tapes_test_file}: {mse}\")\n",
    "    print(f\"RMSE for {tapes_test_file}: {rmse}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总体MSE和RMSE\n",
    "average_mse = np.mean(mse_scores)\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(f\"Average MSE: {average_mse}\")\n",
    "print(f\"Average RMSE: {average_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
